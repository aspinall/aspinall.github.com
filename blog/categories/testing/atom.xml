<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | Craig Aspinall]]></title>
  <link href="http://www.craigaspinall.com/blog/categories/testing/atom.xml" rel="self"/>
  <link href="http://www.craigaspinall.com/"/>
  <updated>2012-06-18T07:33:23+10:00</updated>
  <id>http://www.craigaspinall.com/</id>
  <author>
    <name><![CDATA[Craig Aspinall]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Play!ing with Concordion]]></title>
    <link href="http://www.craigaspinall.com/blog/2012/06/14/playing-with-concordion/"/>
    <updated>2012-06-14T07:42:00+10:00</updated>
    <id>http://www.craigaspinall.com/blog/2012/06/14/playing-with-concordion</id>
    <content type="html"><![CDATA[<p>I've just started experimenting with <a href="http://www.playframework.org">Play! framework 2.0</a>. I was attracted by the static typing and functional nature of <a href="http://www.scala-lang.org">Scala</a>, and the shear testability of Play! applications. It looks like you can test each component of the MVC pattern independently and without going through the UI, and I think in most cases without even starting the server.</p>

<p>As someone who is preaching about testability on a daily basis, I have to investigate further. Of course, the proof of the pudding is in the eating, so I'm going to build and deploy a simple application using it, to see whether it lives up to the promise. I'll track the progress of that application and share any learnings here.</p>

<!--more-->


<p>The first thing I wanted to do was set up a framework for <a href="http://www.specificationbyexample.com">specifying by example</a> with my current BDD tool of choice which is <a href="http://www.concordion.org">Concordion</a>. Turns out that isn't as straight forward as I thought, since Play! uses <a href="https://github.com/harrah/xsbt/wiki">SBT</a> (Scala Build Tool), which is new to me, and Concordion has a few quirks in the way it has to be set up. So here's the first of my learnings, which explains how to get Concordion working in a Play! project.</p>

<p>First of all you need to add a dependency on Concordion:</p>

<p>``` scala Build.scala
object ApplicationBuild extends Build {
...
  val appDependencies = Seq(</p>

<pre><code>"org.concordion" % "concordion" % "1.4.2" % "test"
</code></pre>

<p>  )
...
}
```</p>

<p>Next, you need to instruct SBT to copy the Concordion HTML files to the target folder:</p>

<p>``` scala Build.scala
object ApplicationBuild extends Build {
...
   val main = PlayProject(appName, appVersion, appDependencies, mainLang = SCALA).settings(</p>

<pre><code> unmanagedClasspath in Test &lt;+= (baseDirectory) map { bd =&gt; Attributed.blank(bd / "test") }
</code></pre>

<p>   )
...
}
```</p>

<p>And last but not least, you probably want to tell Concordion to store it's reports somewhere sensible (otherwise it puts them in the <code>java.io.tmpdir</code> folder):</p>

<p><code>scala Build.scala
object ApplicationBuild extends Build {
...
  System.setProperty("concordion.output.dir", "target/test-reports/concordion")
...
}
</code></p>

<p>With that in place, you can create a Concordion HTML specification and store it in the <code>test</code> folder of your project:</p>

<p>``` html ConcordionExample.html
&lt;!DOCTYPE HTML>
<html xmlns:concordion="http://www.concordion.org/2007/concordion">
<head>
  <title>Concordion Example</title>
</head>
<body></p>

<pre><code>&lt;h1&gt;Concordion Example&lt;/h1&gt;
&lt;p&gt;The answer always equals &lt;span concordion:assertEquals="value()"&gt;1&lt;/span&gt;&lt;/p&gt;
</code></pre>

<p></body>
</html>
```</p>

<p>Finally, create a Scala or Java fixture class (note that you need to have a dummy method annotated with the <a href="http://www.junit.org">JUnit</a> <code>@Test</code> annotation for the test to be picked up, I haven't found a better way around this yet):</p>

<p>``` scala ConcordionExampleTest.scala
import org.concordion.integration.junit4.ConcordionRunner
import org.junit.runner.RunWith
import org.junit.Test</p>

<p>@RunWith(classOf[ConcordionRunner])
class ConcordionExampleTest {
  def value = 1</p>

<p>  @Test
  def runThisTest() {}
}
```</p>

<p>``` java ConcordionExampleTest.java
import org.concordion.integration.junit4.ConcordionRunner;
import org.junit.runner.RunWith;
import org.junit.Test;</p>

<p>@RunWith(ConcordionRunner.class)
public class ConcordionExampleTest {</p>

<pre><code>public int value() {
        return 1;
}

@Test
public void runThisTest() {}
</code></pre>

<p>}
```</p>

<p>Then you can run <code>play test</code> and voila, one Concordion specification is executed!</p>

<p>``` plain $ play test
$ play test
[info] Loading project definition from /Users/craigaspinall/Work/scala-concordion-poc/project
[info] Set current project to scala-concordion-poc (in build file:/Users/craigaspinall/Work/scala-concordion-poc/)
[info] Compiling 1 Scala source to /Users/craigaspinall/Work/scala-concordion-poc/target/scala-2.9.1/test-classes...
[info] ConcordionExampleTest
/Users/craigaspinall/Work/scala-concordion-poc/target/test-reports/concordion/ConcordionExample.html
Successes: 1, Failures: 0</p>

<p>[info] + ConcordionExampleTest.runThisTest
[info] + ConcordionExampleTest.[Concordion Specification for 'ConcordionExample']
[info]
[info]
[info] Total for test ConcordionExampleTest
[info] Finished in 0.526 seconds
[info] 2 tests, 0 failures, 0 errors
[info] Passed: : Total 2, Failed 0, Errors 0, Passed 2, Skipped 0
[success] Total time: 2 s, completed 14/06/2012 8:25:08 AM
```</p>

<p>If anyone reading this knows how to avoid the dummy test, then please leave a comment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The role of automated testing]]></title>
    <link href="http://www.craigaspinall.com/blog/2010/11/28/the-role-of-automated-testing/"/>
    <updated>2010-11-28T00:00:00+10:00</updated>
    <id>http://www.craigaspinall.com/blog/2010/11/28/the-role-of-automated-testing</id>
    <content type="html"><![CDATA[<p>Over the last week I've had a lot of discussions about the underlying motive of the roles that my colleagues and I are currently performing. We are responsible for improving the quality of software being produced by the teams we are involved with, and the main focus of our recent work has been creating automation tools to assist the testers. There are three possible motives for our roles:</p>

<h1>to reduce costs</h1>

<h1>to increase productivity</h1>

<h1>to improve quality</h1>

<p>For us it's a simple case of improving quality but that doesn't necessarily mean that our leaders have the same motives. In fairness they do overlap, but focusing too much on any one of them can be to the detriment of the others.</p>

<!--more-->


<p>For example, if you want to reduce costs and automated testing makes the testers four times more productive, then in theory you can remove three quarters of your testers without any loss of quality or productivity. Of course the theory and reality are quite different! Similarly, if you go all out for quality, you may need more people or tools or equipment which will result in increased costs, and progress may be slower.</p>

<p>The catalyst for the discussions was that we just found out that the number of testers is being reduced on one of the projects we're working on and we were horrified. We were very concerned that the work we have been doing was being used to justify cost reductions but fortunately that isn't the case (at least not this time).</p>

<p>Since our goal is to improve quality we expect that any cost savings we enable during development are re-investing into improving quality in other ways. This should include freeing up the testers to do more exploratory testing, but could also include things like performance, security or usability testing that often get overlooked.</p>

<p>Even with that investment, we expect that there will still be an overall reduction in cost, simply because less defects will get to production. The cost of fixing defects increases exponentially the later in the process they are found, because more and more people become involved in the development, testing and technical support of the fix. Unfortunately the total cost of ownership is not easy to quantify and rarely gets the focus it deserves.</p>

<p>"Episode 18":http://goo.gl/Z69dl of the "Coding By Numbers":http://www.codingbynumbers.com podcast (which I co-host) has a much more in depth discussion on this subject if you want to hear more!</p>
]]></content>
  </entry>
  
</feed>
